{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Synapse: read ADF Notebook activity parameters via job tags.\n",
        "# When you run manually in Studio, it falls back to the defaults below.\n",
        "\n",
        "from notebookutils import mssparkutils\n",
        "\n",
        "def get_param(name: str, default: str):\n",
        "    try:\n",
        "        v = mssparkutils.env.getJobTag(name)  # set by ADF baseParameters\n",
        "        if v and v.lower() != \"null\":\n",
        "            return v\n",
        "    except Exception:\n",
        "        pass\n",
        "    return default\n",
        "\n",
        "# ---- set defaults used only when running interactively in Studio ----\n",
        "ingest_date = get_param(\"ingest_date\", \"2025-07-01\")\n",
        "file_name   = get_param(\"file_name\",   \"yellow_tripdata_2025-07.parquet\")\n",
        "\n",
        "print(\"ingest_date:\", ingest_date)\n",
        "print(\"file_name  :\", file_name)\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spsmall01",
              "statement_id": 2,
              "statement_ids": [
                2
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "2",
              "normalized_state": "finished",
              "queued_time": "2025-09-09T23:28:05.2111105Z",
              "session_start_time": "2025-09-09T23:28:05.2120301Z",
              "execution_start_time": "2025-09-09T23:31:38.7533662Z",
              "execution_finish_time": "2025-09-09T23:31:39.0059416Z",
              "parent_msg_id": "d9862c8f-8939-4ac6-97ef-728b6b7128ed"
            },
            "text/plain": "StatementMeta(spsmall01, 2, 2, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ingest_date: 2025-07-01\nfile_name  : yellow_tripdata_2025-07.parquet\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from notebookutils import mssparkutils\n",
        "\n",
        "acct = \"eltazr1adls\"  # your default workspace storage account\n",
        "test_dir = f\"abfss://raw@{acct}.dfs.core.windows.net/_syn_auth_test/\"\n",
        "\n",
        "# Create/list a tiny file. If this fails with auth, fix RBAC on the storage account:\n",
        "# grant Storage Blob Data Contributor to the Synapse workspace's managed identity.\n",
        "mssparkutils.fs.mkdirs(test_dir)\n",
        "mssparkutils.fs.put(test_dir + \"ok.txt\", \"hello\", True)\n",
        "display(mssparkutils.fs.ls(test_dir))\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spsmall01",
              "statement_id": 3,
              "statement_ids": [
                3
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "2",
              "normalized_state": "finished",
              "queued_time": "2025-09-09T23:32:11.6786216Z",
              "session_start_time": null,
              "execution_start_time": "2025-09-09T23:32:11.6798173Z",
              "execution_finish_time": "2025-09-09T23:32:14.5089337Z",
              "parent_msg_id": "40243e24-0c67-4aa8-98e5-af7566e6efba"
            },
            "text/plain": "StatementMeta(spsmall01, 2, 3, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "[FileInfo(path=abfss://raw@eltazr1adls.dfs.core.windows.net/_syn_auth_test/ok.txt, name=ok.txt, size=5)]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from notebookutils import mssparkutils\n",
        "\n",
        "acct = \"eltazr1adls\"\n",
        "\n",
        "src = f\"abfss://raw@{acct}.dfs.core.windows.net/nyc_taxi/ingest_date={ingest_date}/{file_name}\"\n",
        "dst = f\"abfss://raw@{acct}.dfs.core.windows.net/nyc_taxi_snappy/ingest_date={ingest_date}/file_name={file_name}/\"\n",
        "\n",
        "# Read the original parquet (ZSTD), write as Snappy\n",
        "df = spark.read.parquet(src)\n",
        "\n",
        "# If files are big, you may remove coalesce(1); leaving it keeps one snappy file per input file_name\n",
        "(df.coalesce(1)\n",
        "   .write\n",
        "   .mode(\"overwrite\")                # idempotent for reruns/backfills\n",
        "   .option(\"compression\",\"snappy\")\n",
        "   .parquet(dst))\n",
        "\n",
        "print(\"Wrote:\", dst)\n",
        "display(mssparkutils.fs.ls(dst))\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spsmall01",
              "statement_id": 4,
              "statement_ids": [
                4
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "2",
              "normalized_state": "finished",
              "queued_time": "2025-09-09T23:32:35.743795Z",
              "session_start_time": null,
              "execution_start_time": "2025-09-09T23:32:35.745072Z",
              "execution_finish_time": "2025-09-09T23:33:11.3112718Z",
              "parent_msg_id": "32b8ef36-465b-46fd-8c33-264b6b69735a"
            },
            "text/plain": "StatementMeta(spsmall01, 2, 4, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: abfss://raw@eltazr1adls.dfs.core.windows.net/nyc_taxi_snappy/ingest_date=2025-07-01/file_name=yellow_tripdata_2025-07.parquet/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "[FileInfo(path=abfss://raw@eltazr1adls.dfs.core.windows.net/nyc_taxi_snappy/ingest_date=2025-07-01/file_name=yellow_tripdata_2025-07.parquet/_SUCCESS, name=_SUCCESS, size=0),\n FileInfo(path=abfss://raw@eltazr1adls.dfs.core.windows.net/nyc_taxi_snappy/ingest_date=2025-07-01/file_name=yellow_tripdata_2025-07.parquet/part-00000-e4dcff02-b1ac-4c15-9fa9-c689418fd50b-c000.snappy.parquet, name=part-00000-e4dcff02-b1ac-4c15-9fa9-c689418fd50b-c000.snappy.parquet, size=81696094)]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}