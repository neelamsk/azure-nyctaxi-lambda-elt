# Streaming + Batch ELT â†’ Synapse DW (Hourly + Backfill)
![Security Scanned](https://img.shields.io/badge/Security-Scanned%20with%20TruffleHog-green)
![Managed Identity](https://img.shields.io/badge/Auth-Managed%20Identity-blue)
![RBAC](https://img.shields.io/badge/Access-RBAC%20Enabled-blue)

**Oneâ€‘liner:** Event Hubs & ASA land **raw/curated/DLQ** to ADLS; ADF loads Synapse **hourly** (with backfill). Batch ELT shares the **same model**. Power BI shows **Last Updated / Latency** so freshness is clear.

**Why it matters:** Reliable, idempotent warehouse loads with DLQ, alerts, and range backfills. A single source of truth powers BI from both streaming and batch.

---

## Architecture (high level)

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Streaming Lane â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Producer(s) â†’ Event Hubs â†’ Stream Analytics (parse + DQ) â†’ ADLS Gen2
                                     â”œâ”€ Raw JSONL  â†’ streaming/â€¦/date=YYYY/MM/DD/time=HH/â€¦
                                     â”œâ”€ Curated CSV â†’ streaming-curated/â€¦/date=â€¦/time=â€¦/â€¦
                                     â””â”€ DLQ JSON    â†’ streaming-dlq/â€¦/date=â€¦/time=â€¦/â€¦
                                     |
                                     â””â†’ ADF hour pipeline â†’ Synapse (stg â†’ slice â†’ dims â†’ fact)
                                              â””â†’ Backfill wrapper (lastHour | fixedHour | range)

                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Batch ELT Lane â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Batch files (landing) â†’ ADF (copy/transform) â†’ Synapse (stg â†’ core â†’ mdl.* same model tables)

Power BI â†’ reads from Synapse view (shared by batch & streaming)
```

**Core ideas**
- **Separate concerns**: stream continuously to the lake; microâ€‘batch the warehouse (hourly) for reliability & cost.
- **Synapseâ€‘safe upsert**: updateâ€‘thenâ€‘insert (no reliance on `@@ROWCOUNT`/`MERGE OUTPUT`). 
- **Runâ€‘scoped purge**: delete `core.trip_clean_slice` by `_runId` after each model load (clean reruns/backfills).
- **Shared model**: both lanes feed `mdl.fact_trip` & dims â†’ BI stays unchanged.

---

## Whatâ€™s included

- **Streaming**
  - ASA wiring: parse/enrich; three sinks (raw/curated/DLQ) with hourly partitioning.
  - ADF hour pipeline: Copy curated â†’ staging; build slice; upsert dims & fact; purge slice; log.
  - Backfill: wrapper supports **lastHour / fixedHour / range** (hourâ€‘byâ€‘hour loop).
- **Batch ELT**
  - Existing pipelines to load the same **mdl** model (fact + dims), aligned keys.
- **Model**
  - `mdl.fact_trip`: `CHAR(64)` SHAâ€‘256 `trip_id`, **DISTRIBUTION = HASH(trip_id)**, **CLUSTERED COLUMNSTORE**.
  - Dims: vendor, payment, location (replicate). Rate/flag optional.
  - BI view: `mdl.vw_fact_trip_bi` (flattened with freshness fields).
- **BI**
  - Power BI report with **Trips**, **Total Fare**, **Tip %**, **Last Updated (UTC)** & **Latency (min)** cards.
- **Ops**
  - Hourly trigger; Azure Monitor alerts (ADF/ASA/EH/SQL); ADLS lifecycle rules; RBAC via MSI where possible.

---

## Key design choices (short)

- **Idempotent upsert**: stage â†’ **UPDATE** matched diffs â†’ **INSERT** new â†’ counts via temp tables; expose counts via a 1â€‘row `SELECT` or log inside SP.
- **Distribution strategy**: big fact **HASH(trip_id)** + CCI; small dims **REPLICATE** â†’ avoids runtime **shuffles**.
- **Backfill simplicity**: wrapper with an **Until** loop: process hour â†’ bump hour â†’ repeat.
- **Quality**: curated = rows that pass DQ; DLQ = rejects with reason; raw = full fidelity.

---

## Quality & lineage (optional roadmap)

- **Rowâ€‘level data quality counters** *(M)*  
  Count per run: `good_rows`, `dlq_rows`, `negative_fare`, `bad_duration`, `null_vendor`, etc. Log in audit or a dedicated table.
- **Purview lineage** *(L)*  
  Register EH, ASA, ADLS, ADF, Synapse. Expected lineage: **EH â†’ ASA â†’ ADLS â†’ ADF â†’ Synapse**.

---

## Operating the solution (at a glance)

- **Hourly**: trigger runs the hour pipeline for the **last completed hour**.
- **Backfill**: set `startHourUtc`/`endHourUtc` (ISO hour). Wrapper loops hours and calls the hour pipeline each iteration.
- **Reruns**: safe; runâ€‘scoped purge ensures clean idempotent loads.
- **Alerts** (Azure Monitor): 
  - ADF: Pipeline/Activity failed runs.
  - ASA: Watermark delay/backlog, job status.
  - Event Hubs: Throttled requests, server errors.
  - Synapse: CPU/tempdb/queue depth.
  - Storage (optional): availability/5xx.
- **Lifecycle**: curated â†’ Cool @7d, delete @30â€“60d; DLQ longer; staging cleanup @7d.

---

## Verification quick checks

- Slice purged: `SELECT COUNT(*) FROM core.trip_clean_slice WHERE _runId='<RunId>';` â†’ **0**.
- Fact touched recently: `SELECT TOP 5 trip_id, last_upsert_at FROM mdl.fact_trip ORDER BY last_upsert_at DESC;`.
- Power BI freshness: **Last Updated** card matches last successful hour; **Latency (min)** sane.

---

## Repo map

```
/infra        # Bicep/ARM + GitHub Actions (deploy EH/ASA/ADLS/alerts/pipelines)
/asa          # asa-wire.sh (job wiring + inputs/outputs/query)
/adf          # pipelines (JSON); backfill wrapper + range
/sql          # DDL (tables); procs (slice/dims/fact/purge); BI view
/bi           # PBIX or screenshots
README.md     # (this file) â€” high-level overview
README_BATCHELT.md   # Batch ELT details
README_STREAMING.md  # Streaming details
```
---

## ğŸ”’ Security Practices

This repository has been scanned for security vulnerabilities and secrets:
- **Secret Scanning**: Verified using [TruffleHog](https://github.com/trufflesecurity/trufflehog) - no secrets detected
- **Managed Identities**: All Azure authentication uses system-assigned managed identities
- **RBAC**: Least privilege access implemented across all resources
- **Environment Variables**: Sensitive configuration stored in GitHub Environment Secrets (not in code)
```bash
# Security scan performed with:
trufflehog --regex --entropy=False https://github.com/neelamsk/azure-nyctaxi-lambda-elt

---

## Glossary (2 lines each)

- **OLTP vs OLAP** â€” app DB for transactions vs. warehouse for analytics.  
- **MPP** â€” massively parallel workers; avoid **shuffles** via **HASH(key)** on big joins, **REPLICATE** small dims.  
- **CTAS + CCI** â€” fast (re)build with the right distribution; columnstore for scan speed.  
- **DLQ** â€” rejected rows with a reason; curated ingests only good rows.

---

## Links

- **Batch ELT (detailed):** `README_BATCHELT.md`  
- **Streaming (detailed):** `README_STREAMING.md`

---

## License
MIT (or your preferred license).
